一、项目概述

  本项目基于美国南瓜市场数据（`US-pumpkins.csv`），构建了多种回归模型预测南瓜的最低价格（Low Price）和最高价格（High Price）。通过数据预处理、多模型对比、参数优化及结果分析，探索南瓜价格的关键影响因素及最优预测模型。

二、南瓜数据细节分析

  通过数据加载与预处理过程，对南瓜数据的核心特征及分布有以下关键发现：
  
1. 数据基本结构
	原始数据包含多种特征，经清洗后保留有效特征：‘City Name’、‘Package’、‘Variety’、‘Date’、‘Origin’、‘Item Size’、‘Color’、‘Repack’、‘Mostly Low’、‘Mostly High’等。
目标变量为‘Low Price’（最低价格）和‘High Price’（最高价格），用于双目标预测。
2. 特征分布与价值分析
<img width="872" height="511" alt="image" src="https://github.com/user-attachments/assets/716033b7-d1c8-4262-abdc-ac4d78f519cb" />

3. 缺失值情况
   
  预处理前存在高缺失值列：`Type`、`Sub Variety`、`Origin District`等（缺失值占比极高），已通过`columns_to_drop`删除。
  核心特征缺失值处理：分类特征用众数填充（如`Variety`、`Origin`），数值特征用中位数填充（如`Mostly Low`、`Mostly High`），确保模型输入完整性。

二、特征处理细节

  本项目的特征处理流程围绕数据清洗、转换及优化展开，关键细节如下：
  
1. 特征选择与清洗
   
  删除冗余特征：移除全空列（缺失值等于样本量的列）、低价值列（如`Unit of Sale`、`Unnamed: 25`），减少噪声干扰。
  
  保留核心特征：聚焦与价格强相关的特征（如`Package`、`Item Size`），剔除无实际意义的特征（如`Sub Variety`）。
  
2. 特征转换与编码

  独热编码（One-Hot Encoding）：对分类特征（`City Name`、`Variety`、`Origin`等）进行编码，将离散值转换为模型可识别的数值特征，代码中通过`pd.get_dummies`实现，并处理特征名空格（`str.replace(' ', '_')`）。

  目标变量处理：对`Low Price`和`High Price`分别建模，实现双目标预测，保留原始真实值用于后续结果对比。
  
3. 缺失值处理策略

  分类特征：用众数填充（如`Variety`的主流品种），保存填充值（`cat_fill_values`）用于一致性处理。
  
  数值特征：用中位数填充（如`Mostly Low`），避免极端值影响（`num_fill_values`记录填充值）。
  
  预处理后缺失值检查显示核心特征无缺失，确保模型训练稳定性。
  
4. 特征处理对模型的影响
  独热编码导致特征维度增加，但树模型（如RandomForest、XGBoost）对高维数据适应性较强，而线性模型（如Ridge、Lasso）可能受多重共线性影响。
  缺失值填充策略保留了样本量，避免因删除缺失样本导致的数据损失。

三、模型细节分析

  本项目训练了多种回归模型并进行优化，核心发现如下：
  
1. 模型选择与训练策略

  基础模型集：包含8种经典回归模型，覆盖线性、树型、集成及近邻算法：
<img width="650" height="284" alt="image" src="https://github.com/user-attachments/assets/dea0e2d1-9e4a-4a01-bcd5-98a32698b25e" />
  
  交叉验证：采用5折交叉验证（`KFold(n_splits=5)`），确保模型评估稳定性，记录每折训练/验证样本量，统一折划分标准（所有模型共享相同折索引）。
  
2. 模型评估指标
   
  核心指标：均方误差（MSE）和决定系数（R²），其中：
  
    MSE反映预测值与真实值的平均平方误差，值越小越好；
    
    R²反映模型对目标变量变异的解释程度，越接近1性能越好。
    
3. 模型优化

  参数调优：通过`optimize_random_forest_custom`函数调整关键参数。

<img width="730" height="78" alt="image" src="https://github.com/user-attachments/assets/688f47c0-125e-40af-9dda-d374b2607e3c" />
    
    `n_estimators`：树的数量，影响模型稳定性（过少易欠拟合，过多增加计算成本）；
    
    `max_depth`：树深度，控制过拟合风险（过深易过拟合，过浅欠拟合）；
    
    `min_samples_split`/`min_samples_leaf`：控制节点分裂条件，避免过拟合。
  优化效果：调参后的随机森林在测试集R²虽然有所降低，但通过打印决策树可发现模型在实际应用中的可应用型更强。
4. 模型性能对比

  最佳模型分析：
  
    最低价格（Low Price）：XGBoost模型表现最优，R²最高且MSE最低；
    
    最高价格（High Price）：XGBoost模型表现最优，树模型整体优于线性模型（如Ridge、Lasso）。
    
  树模型优势：通过`plot_tree`可视化决策树，可直观解释特征对价格的影响（如`Package`规格直接决定价格区间），线性模型则难以捕捉非线性关系。
  
四、开放问题思考
1. 特征选择方法

可通过以下方式优化特征选择：

 	 基于树模型特征重要性（如`feature_importances_`）剔除低贡献特征；
  	
  	方差过滤：移除方差接近0的常量特征（如单一值占比过高的特征）；
  
  	相关性分析：计算特征与目标变量的皮尔逊/斯皮尔曼相关系数，保留高相关特征；
  
  	递归特征消除（RFE）：逐步剔除低重要性特征，迭代优化特征集。
  
2. 回归模型评估指标的局限性
   
  R²：反映模型解释度，但样本分布不均时可能高估性能（如极端值少的数据集）；
  
  MSE/RMSE：对异常值敏感，可能放大极端误差；
  
  MAE：更稳健但忽略误差平方关系。需结合多种指标（如调整后R²、MAPE）综合评估，尤其关注实际业务场景需求（如价格预测对极端值的容忍度）。
  
3. 树模型性能分析
   
  在本项目中表现优异，原因包括：
  
  	天然处理非线性关系（如规格与价格的非线性关联）；
  
  	对分类特征友好，无需复杂编码转换；
  
  	抗多重共线性能力强，适合高维数据（如独热编码后的特征）。
  
  	局限性：需谨慎调参避免过拟合，计算成本高于线性模型。
  
4. 支持向量机（SVM）非线性核的适用性

  SVM适合高维数据的原因：通过核函数（如RBF）将低维特征映射到高维空间，在高维空间中更容易找到线性分隔超平面，尤其适合特征维度高但样本量不大的场景（如本项目经独热编码后的特征）。
本项目中SVM原始性能一般，可能因参数未优化（如`C`、`gamma`），需进一步调优释放潜力。

5. 建模难点
   
  特征工程：如何从原始数据中提取有效特征（如日期中的季节信息、规格的量化转换）是核心挑战；

  数据分布不均：部分类别样本少（如小众产地、特殊规格），导致模型对边缘案例预测不准；
  
  参数调优：不同模型对超参数敏感（如XGBoost的`learning_rate`、树模型的`max_depth`），需平衡性能与效率；
  
  目标一致性：`Low Price`和`High Price`的最佳模型可能不同，需兼顾双目标优化。


四、项目结构与结果

  代码核心功能：数据加载→预处理→多模型训练→交叉验证→参数优化→结果可视化→保存预测结果。
  
  输出文件：所有模型预测结果（`pumpkin_price_predictions`文件夹）及实验结果（`model_experiment_results.csv`）。







